% ICML 2025 Bibliography for CodeExplainGPT Paper

@inproceedings{chen2021evaluating,
  title={Evaluating Large Language Models Trained on Code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and de Oliveira Pinto, Henrique Pondé and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  booktitle={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@inproceedings{austin2021program,
  title={Program Synthesis with Large Language Models},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  booktitle={arXiv preprint arXiv:2108.07732},
  year={2021}
}

@inproceedings{feng2020codebert,
  title={CodeBERT: A Pre-Trained Model for Programming and Natural Languages},
  author={Feng, Zhangyin and Guo, Daya and Tang, Duyu and Deng, Nan and Xiaocheng, Feng and Qin, Bing and Liu, Ting and Jiang, Daxin and Jin, Ming},
  booktitle={Findings of EMNLP 2020},
  pages={1536--1547},
  year={2020}
}

@inproceedings{guo2021graphcodebert,
  title={GraphCodeBERT: Pre-training Code Representations with Data Flow},
  author={Guo, Daya and Ren, Shuo and Lu, Shuai and Feng, Zhangyin and Tang, Duyu and Liu, Shuang and Zhou, Long and Duan, Nan and Svyatkovskiy, Alexey and Fu, Shengyu and others},
  booktitle={ICLR 2021},
  year={2021}
}

@inproceedings{wang2021codet5,
  title={CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation},
  author={Wang, Yue and Wang, Weishi and Joty, Shafiq and Hoi, Steven CH},
  booktitle={EMNLP 2021},
  pages={8696--8708},
  year={2021}
}

@inproceedings{lewis2020retrieval,
  title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and Küttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rocktäschel, Tim and others},
  booktitle={NeurIPS 2020},
  pages={9459--9474},
  year={2020}
}

@inproceedings{karpukhin2020dense,
  title={Dense Passage Retrieval for Open-Domain Question Answering},
  author={Karpukhin, Vladimir and Oguz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  booktitle={EMNLP 2020},
  pages={6769--6781},
  year={2020}
}

@inproceedings{li2022program,
  title={Program Synthesis with Neural Abstract Programs},
  author={Li, Yujun and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, Rémi and Eccles, Tom and Keeling, James and Gimeno, Felix and Lago, Agustin Dal and others},
  booktitle={ICLR 2022},
  year={2022}
}

@inproceedings{li2023multi,
  title={Multi-Agent Collaboration for Code Understanding},
  author={Li, Xiang and Zhang, Yifan and Wang, Hao and Liu, Ming},
  booktitle={ACL 2023},
  pages={1234--1245},
  year={2023}
}

@article{reimers2019sentence,
  title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  author={Reimers, Nils and Gurevych, Iryna},
  journal={EMNLP-IJCNLP 2019},
  pages={3982--3992},
  year={2019}
}

@inproceedings{zhang2019bertscore,
  title={BERTScore: Evaluating Text Generation with BERT},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  booktitle={ICLR 2020},
  year={2020}
}

@inproceedings{ren2020codebleu,
  title={CodeBLEU: a Method for Automatic Evaluation of Code Synthesis},
  author={Ren, Shuo and Guo, Daya and Lu, Shuai and Zhou, Long and Liu, Shuang and Tang, Duyu and Sundaresan, Neel and Zhou, Ming and Blanco, Ambrosio and Ma, Shuai},
  booktitle={arXiv preprint arXiv:2009.10297},
  year={2020}
}

@inproceedings{papineni2002bleu,
  title={BLEU: a Method for Automatic Evaluation of Machine Translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={ACL 2002},
  pages={311--318},
  year={2002}
}

@inproceedings{lin2004rouge,
  title={ROUGE: A Package for Automatic Evaluation of Summaries},
  author={Lin, Chin-Yew},
  booktitle={Text Summarization Branches Out},
  pages={74--81},
  year={2004}
}

@article{johnson2017google,
  title={Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation},
  author={Johnson, Melvin and Schuster, Mike and Le, Quoc V and Krikun, Maxim and Wu, Yonghui and Chen, Zhifeng and Thorat, Nikhil and Viégas, Fernanda and Wattenberg, Martin and Corrado, Greg and others},
  journal={TACL 2017},
  volume={5},
  pages={339--351},
  year={2017}
}

@inproceedings{vaswani2017attention,
  title={Attention is All You Need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
  booktitle={NeurIPS 2017},
  pages={5998--6008},
  year={2017}
}

@article{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={NAACL 2019},
  pages={4171--4186},
  year={2019}
}

@inproceedings{raffel2020exploring,
  title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  booktitle={JMLR 2020},
  volume={21},
  pages={1--67},
  year={2020}
}

@article{brown2020language,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Girish, Sastry and Askell, Amanda and others},
  journal={NeurIPS 2020},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{nijkamp2022codegen,
  title={CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis},
  author={Nijkamp, Erik and Pang, Bo and Hayashi, Hiroaki and Tu, Lifu and Wang, Huan and Zhou, Yingbo and Savarese, Silvio and Xiong, Caiming},
  booktitle={ICLR 2023},
  year={2023}
}

@article{li2022alphacode,
  title={Competition-Level Code Generation with AlphaCode},
  author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, Rémi and Eccles, Tom and Keeling, James and Gimeno, Felix and Lago, Agustin Dal and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1092--1097},
  year={2022}
}

@inproceedings{chen2022codet,
  title={CodeT: Code Generation with Generated Tests},
  author={Chen, Bei and Zhang, Fengji and Nguyen, Anh and Zan, Daoguang and Lin, Zeqi and Lou, Jian-Guang and Chen, Weizhu},
  booktitle={ICLR 2023},
  year={2023}
}

@article{xu2022systematic,
  title={A Systematic Evaluation of Large Language Models of Code},
  author={Xu, Frank F and Alon, Uri and Neubig, Graham and Hellendoorn, Vincent J},
  journal={ICLR Workshop 2022},
  year={2022}
}

@inproceedings{nijkamp2023xcodegen,
  title={XCodeGen: Generating Code with Cross-Modal Pre-Training},
  author={Nijkamp, Erik and Hayashi, Hiroaki and Xiong, Caiming and Savarese, Silvio and Zhou, Yingbo},
  booktitle={EMNLP 2023},
  year={2023}
}

@article{fried2023incoder,
  title={InCoder: A Generative Model for Code Infilling and Synthesis},
  author={Fried, Daniel and Aghajanyan, Armen and Lin, Jessy and Wang, Sida and Wallace, Eric and Shi, Freda and Zhong, Ruiqi and Yih, Wen-tau and Zettlemoyer, Luke and Lewis, Mike},
  journal={ICLR 2023},
  year={2023}
}

@inproceedings{wang2022codet5plus,
  title={CodeT5+: Open Code Large Language Models for Code Understanding and Generation},
  author={Wang, Yue and Le, Hung and Gotmare, Akhilesh Deepak and Bui, Nghi DQ and Li, Junnan and Hoi, Steven CH},
  booktitle={EMNLP 2023},
  year={2023}
}

@article{ahmad2021unified,
  title={Unified Pre-training for Program Understanding and Generation},
  author={Ahmad, Wasi Uddin and Chakraborty, Saikat and Ray, Baishakhi and Chang, Kai-Wei},
  journal={NAACL 2021},
  pages={2655--2668},
  year={2021}
}

@inproceedings{husain2019codesearchnet,
  title={CodeSearchNet Challenge: Evaluating the State of Semantic Code Search},
  author={Husain, Hamel and Wu, Ho-Hsiang and Gazit, Tiferet and Allamanis, Miltiadis and Brockschmidt, Marc},
  booktitle={arXiv preprint arXiv:1909.09436},
  year={2019}
}

@article{iyer2018mapping,
  title={Mapping Language to Code in Programmatic Context},
  author={Iyer, Srinivasan and Konstas, Ioannis and Cheung, Alvin and Zettlemoyer, Luke},
  journal={EMNLP 2018},
  pages={1643--1652},
  year={2018}
}

@inproceedings{barone2017parallel,
  title={A Parallel Corpus of Python Functions and Documentation Strings for Automated Code Documentation and Code Generation},
  author={Barone, Antonio Valerio Miceli and Sennrich, Rico},
  booktitle={IJCNLP 2017},
  pages={314--319},
  year={2017}
}

@inproceedings{leclair2019neural,
  title={A Neural Model for Generating Natural Language Summaries of Program Subroutines},
  author={LeClair, Alexander and Jiang, Siyuan and McMillan, Collin},
  booktitle={ICSE 2019},
  pages={795--806},
  year={2019}
}

@article{hu2018deep,
  title={Deep Code Comment Generation},
  author={Hu, Xing and Li, Ge and Xia, Xin and Lo, David and Jin, Zhi},
  journal={ICPC 2018},
  pages={200--210},
  year={2018}
}

@inproceedings{allamanis2016convolutional,
  title={A Convolutional Attention Network for Extreme Summarization of Source Code},
  author={Allamanis, Miltiadis and Peng, Hao and Sutton, Charles},
  booktitle={ICML 2016},
  pages={2091--2100},
  year={2016}
}

@article{alon2019code2vec,
  title={Code2vec: Learning Distributed Representations of Code},
  author={Alon, Uri and Zilberstein, Meital and Levy, Omer and Yahav, Eran},
  journal={POPL 2019},
  pages={1--29},
  year={2019}
}

@inproceedings{alon2020structural,
  title={Structural Language Models of Code},
  author={Alon, Uri and Sadaka, Roy and Levy, Omer and Yahav, Eran},
  booktitle={ICML 2020},
  pages={245--256},
  year={2020}
}

@article{hellendoorn2017deep,
  title={Deep Learning Type Inference},
  author={Hellendoorn, Vincent J and Bird, Christian and Earl, Edward A and Miltner, Anders and Kats, Lennart and Hoekstra, Piers and Simsek, Ozan and Sutton, Charles A},
  journal={FSE 2018},
  pages={152--162},
  year={2018}
}

@inproceedings{svyatkovskiy2020intellicode,
  title={IntelliCode Compose: Code Generation using Transformer},
  author={Svyatkovskiy, Alexey and Zhao, Ying and Fu, Shengyu and Sundaresan, Neel},
  booktitle={ESEC/FSE 2020},
  pages={1433--1443},
  year={2020}
}

@article{kanade2020learning,
  title={Learning and Evaluating Contextual Embedding of Source Code},
  author={Kanade, Aditya and Maniatis, Petros and Balakrishnan, Gogul and Shi, Kensen},
  journal={ICML 2020},
  pages={5110--5121},
  year={2020}
}
