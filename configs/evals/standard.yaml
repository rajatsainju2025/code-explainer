# Standard evaluation configuration
name: "standard_eval"
description: "Standard evaluation with comprehensive metrics and settings"

model:
  name: "codet5-base"
  max_length: 512
  temperature: 0.1
  top_p: 0.9
  device: "auto"

retrieval:
  enabled: true
  top_k: 10
  similarity_threshold: 0.7
  rerank: true
  rerank_model: "cross-encoder/ms-marco-MiniLM-L-12-v2"

metrics:
  metrics: ["accuracy", "bleu", "rouge_l", "latency", "cost"]
  bootstrap_samples: 1000
  confidence_level: 0.95
  significance_level: 0.05

dataset:
  eval_path: "data/eval.json"
  max_samples: 100
  shuffle: true
  stratify: false

seed: 42
output_dir: "results/standard_eval"
save_predictions: true
save_metrics: true
batch_size: 1
num_workers: 1
verbose: true
